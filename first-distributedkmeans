//基于spark的分布式k-means
//数据量大小和数量，处理的复杂度，集群的机器数量以及相连带宽都高时使用分布式，比较有优势。
//假设m个n维向量组成的数据集已经规整化,存放在test中


//第一部分，假设集群环境配置已经完成（standalone），导入数据到集群中
//对于批量小的数据，可以复制拷贝
//规模大的可以使用hadoop的hdfs
//
./hadoop fs -put  test.txt  .//将test 放入到hdfs中 

//第二部分
//K-means.py
#coding:utf-8
from numpy import array
from math import sqrt
from pyspark import SparkContext
from pyspark.mllib.clustering import KMeans, KMeansModel


if __name__ == "__main__":
    sc = SparkContext(appName="KMeans",master='local')  # SparkContext


    # 读取并处理数据
    data = sc.textFile("hdsf中test.txt路径")
    print data.collect()
    parsedData = data.map(lambda line: array([float(x) for x in line.split(' ')]))

    # 训练数据
    print parsedData.collect()
    clusters = KMeans.train(parsedData, k=N, maxIterations=M,
                            runs=T, initializationMode="random")//N,M,T根据情况调整

    #求方差之和
    def error(point):
        center = clusters.centers[clusters.predict(point)]
        return sqrt(sum([x**2 for x in (point - center)]))
    WSSSE = parsedData.map(lambda point: error(point)).reduce(lambda x, y: x + y)

    print("Within Set Sum of Squared Error = " + str(WSSSE))

    #聚类结果
    def sort(point):
        return clusters.predict(point)
    clusters_result = parsedData.map(sort)
    #保存 下载模型
    print '聚类结果：'
    print clusters_result.collect()
    sc.stop()

//第三部分
//将程序提交给集群，参数未配置

./bin/spark-submit \
  --class <main-class> \
  --master <master-url> \
  --deploy-mode <deploy-mode> \
  --conf <key>=<value> \
  ... # other options
  <application-jar> \
  [application-arguments]
